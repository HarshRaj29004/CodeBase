{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6307010,"sourceType":"datasetVersion","datasetId":3628528},{"sourceId":9772788,"sourceType":"datasetVersion","datasetId":5986209}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T05:13:22.716247Z","iopub.execute_input":"2024-11-01T05:13:22.716899Z","iopub.status.idle":"2024-11-01T05:13:22.725805Z","shell.execute_reply.started":"2024-11-01T05:13:22.716869Z","shell.execute_reply":"2024-11-01T05:13:22.724957Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/chatbox-faq/chatbox.json\n/kaggle/input/chatbot-dataset/dataset.json\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nimport torch\nimport torch.nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nimport json ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T05:13:22.727340Z","iopub.execute_input":"2024-11-01T05:13:22.727603Z","iopub.status.idle":"2024-11-01T05:13:22.740408Z","shell.execute_reply.started":"2024-11-01T05:13:22.727580Z","shell.execute_reply":"2024-11-01T05:13:22.739546Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"data_path = '/kaggle/input/chatbot-dataset/dataset.json'","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.741338Z","iopub.execute_input":"2024-11-01T05:13:22.741581Z","iopub.status.idle":"2024-11-01T05:13:22.750187Z","shell.execute_reply.started":"2024-11-01T05:13:22.741560Z","shell.execute_reply":"2024-11-01T05:13:22.749297Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# PREPARE DATA","metadata":{}},{"cell_type":"code","source":"with open(data_path, 'r') as f:\n    data = json.load(f)\n    \ntexts = [i['Question'] for i in data]\n# texts = sorted(set(texts), key=texts.index)\nlabels = [index for index, _ in enumerate(texts)]","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.751948Z","iopub.execute_input":"2024-11-01T05:13:22.752230Z","iopub.status.idle":"2024-11-01T05:13:22.760926Z","shell.execute_reply.started":"2024-11-01T05:13:22.752207Z","shell.execute_reply":"2024-11-01T05:13:22.760203Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"for i in range(10):  # Print the first 10 labels and corresponding texts\n    print(f\"Label: {labels[i]}, Text: {texts[i]}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.761933Z","iopub.execute_input":"2024-11-01T05:13:22.762243Z","iopub.status.idle":"2024-11-01T05:13:22.770375Z","shell.execute_reply.started":"2024-11-01T05:13:22.762220Z","shell.execute_reply":"2024-11-01T05:13:22.769492Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Label: 0, Text: How can I register for the hackathon online?\nLabel: 1, Text: Is there an offline registration option?\nLabel: 2, Text: What is the registration link?\nLabel: 3, Text: Is there a registration form I need to fill out?\nLabel: 4, Text: Do I need to create an account to register?\nLabel: 5, Text: Can I register using my social media account?\nLabel: 6, Text: Is there a minimum age requirement for registration?\nLabel: 7, Text: Can I register if I'm a student?\nLabel: 8, Text: Can I register if I'm a professional?\nLabel: 9, Text: Can I register if I'm from outside the city/state/country?\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# PREPROCESSING","metadata":{}},{"cell_type":"code","source":"model_name = 'distilbert-base-uncased'\ntokenizer = DistilBertTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.771382Z","iopub.execute_input":"2024-11-01T05:13:22.771660Z","iopub.status.idle":"2024-11-01T05:13:22.906580Z","shell.execute_reply.started":"2024-11-01T05:13:22.771637Z","shell.execute_reply":"2024-11-01T05:13:22.905707Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n# labels = torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.907736Z","iopub.execute_input":"2024-11-01T05:13:22.908311Z","iopub.status.idle":"2024-11-01T05:13:22.942819Z","shell.execute_reply.started":"2024-11-01T05:13:22.908278Z","shell.execute_reply":"2024-11-01T05:13:22.942164Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class SentimentDataset(torch.utils.data.Dataset):\n    def __init__(self, input_ids, attention_mask, labels):\n        self.input_ids = input_ids\n        self.attention_mask = attention_mask\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.input_ids[idx],\n            'attention_mask': self.attention_mask[idx],\n            'labels': torch.tensor(self.labels[idx])\n        }\n\n# Create dataset and dataloader\ndataset = SentimentDataset(\n    input_ids=inputs['input_ids'],\n    attention_mask=inputs['attention_mask'],\n    labels=labels\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.943702Z","iopub.execute_input":"2024-11-01T05:13:22.943931Z","iopub.status.idle":"2024-11-01T05:13:22.950306Z","shell.execute_reply.started":"2024-11-01T05:13:22.943910Z","shell.execute_reply":"2024-11-01T05:13:22.949455Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.951422Z","iopub.execute_input":"2024-11-01T05:13:22.951742Z","iopub.status.idle":"2024-11-01T05:13:22.965063Z","shell.execute_reply.started":"2024-11-01T05:13:22.951713Z","shell.execute_reply":"2024-11-01T05:13:22.964185Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# PREPARE MODEL","metadata":{}},{"cell_type":"code","source":"model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels = len(labels))","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:22.967493Z","iopub.execute_input":"2024-11-01T05:13:22.967750Z","iopub.status.idle":"2024-11-01T05:13:23.785700Z","shell.execute_reply.started":"2024-11-01T05:13:22.967728Z","shell.execute_reply":"2024-11-01T05:13:23.784820Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:13:23.786969Z","iopub.execute_input":"2024-11-01T05:13:23.787334Z","iopub.status.idle":"2024-11-01T05:13:23.804110Z","shell.execute_reply.started":"2024-11-01T05:13:23.787300Z","shell.execute_reply":"2024-11-01T05:13:23.803230Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# TRAIN","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\nnum_epochs = 6\n\n# Assuming you have a separate dataloader for validation data named 'val_dataloader'\n# and a model named 'model'\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    total_correct = 0\n    total_samples = 0\n\n    # Training loop\n    progress_bar = tqdm(enumerate(dataloader, 1), total=len(dataloader))\n    for step, batch in progress_bar:\n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss = criterion(outputs.logits, batch['labels'])\n        loss.backward()\n        optimizer.step()\n\n        # Calculate accuracy\n        predictions = torch.argmax(outputs.logits, dim=1)\n        correct = (predictions == batch['labels']).sum().item()\n        total_correct += correct\n        total_samples += len(batch['labels'])\n\n        # Accumulate loss\n        total_loss += loss.item()\n\n        progress_bar.set_description(f'Epoch {epoch+1}/{num_epochs}, Step {step}/{len(dataloader)}')\n        progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': correct / len(batch['labels'])})\n\n    # Calculate training statistics for the epoch\n    epoch_loss = total_loss / len(dataloader)\n    epoch_accuracy = total_correct / total_samples\n\n    # Validation loop\n    model.eval()\n    val_total_loss = 0\n    val_total_correct = 0\n    val_total_samples = 0\n\n    with torch.no_grad():\n        for val_step, val_batch in enumerate(dataloader, 1):\n            val_outputs = model(**val_batch)\n            val_loss = criterion(val_outputs.logits, val_batch['labels'])\n\n            # Calculate accuracy\n            val_predictions = torch.argmax(val_outputs.logits, dim=1)\n            val_correct = (val_predictions == val_batch['labels']).sum().item()\n            val_total_correct += val_correct\n            val_total_samples += len(val_batch['labels'])\n\n            # Accumulate loss\n            val_total_loss += val_loss.item()\n\n    # Calculate validation statistics for the epoch\n    val_epoch_loss = val_total_loss / len(dataloader)\n    val_epoch_accuracy = val_total_correct / val_total_samples\n\n    # Print statistics for the epoch\n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:07:55.713580Z","iopub.execute_input":"2024-11-01T06:07:55.714500Z","iopub.status.idle":"2024-11-01T06:08:20.188732Z","shell.execute_reply.started":"2024-11-01T06:07:55.714466Z","shell.execute_reply":"2024-11-01T06:08:20.187800Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/6, Step 5/5: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s, Loss=2.99, Accuracy=1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/6, Loss: 2.9580, Accuracy: 1.0000, Val Loss: 2.9059, Val Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/6, Step 5/5: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s, Loss=2.85, Accuracy=1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/6, Loss: 2.8812, Accuracy: 1.0000, Val Loss: 2.8281, Val Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/6, Step 5/5: 100%|██████████| 5/5 [00:03<00:00,  1.51it/s, Loss=2.77, Accuracy=1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/6, Loss: 2.8078, Accuracy: 1.0000, Val Loss: 2.7619, Val Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/6, Step 5/5: 100%|██████████| 5/5 [00:03<00:00,  1.25it/s, Loss=2.71, Accuracy=1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/6, Loss: 2.7359, Accuracy: 1.0000, Val Loss: 2.6823, Val Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/6, Step 5/5: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s, Loss=2.62, Accuracy=1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/6, Loss: 2.6667, Accuracy: 1.0000, Val Loss: 2.6168, Val Accuracy: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/6, Step 5/5: 100%|██████████| 5/5 [00:03<00:00,  1.46it/s, Loss=2.58, Accuracy=1]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/6, Loss: 2.6013, Accuracy: 1.0000, Val Loss: 2.5602, Val Accuracy: 1.0000\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"# PREDICT","metadata":{}},{"cell_type":"code","source":"def get_response(input_text):\n    # Preprocess input text\n    inputs = tokenizer(input_text, return_tensors=\"pt\")\n    \n    # Step 5: Inference\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n    \n    # Convert logits to probabilities and get predicted label\n    probabilities = torch.softmax(logits, dim=-1)\n    predicted_label = torch.argmax(probabilities, dim=-1).item()\n    \n    # Retrieve corresponding answer based on predicted label\n    response = data[predicted_label]['Answer']\n    \n    return response","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:07:31.357234Z","iopub.execute_input":"2024-11-01T06:07:31.358125Z","iopub.status.idle":"2024-11-01T06:07:31.363930Z","shell.execute_reply.started":"2024-11-01T06:07:31.358090Z","shell.execute_reply":"2024-11-01T06:07:31.362982Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"text_for_pred = 'how to register to hackathon?'\nget_response(text_for_pred)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:13:06.489551Z","iopub.execute_input":"2024-11-01T06:13:06.490195Z","iopub.status.idle":"2024-11-01T06:13:06.528836Z","shell.execute_reply.started":"2024-11-01T06:13:06.490165Z","shell.execute_reply":"2024-11-01T06:13:06.527890Z"},"trusted":true},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'You can register for the hackathon by visiting the Devfolio website. Simply navigate to the registration section to get started!'"},"metadata":{}}],"execution_count":43}]}